{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from resnet_builder import resnet\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import  img_to_array, load_img\n",
    "from PIL import Image\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.python.keras.applications import ResNet50\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization\n",
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (256, 256)\n",
    "nbofdata=700\n",
    "base_path = r'ml100-03-final/image_data/train/'\n",
    "layers_of_folders=0\n",
    "folder_list=[]    \n",
    "categories=['daisy','dandelion', 'rose', 'sunflower', 'tulip']\n",
    "\n",
    "if base_path :\n",
    "    folder_layers=[]\n",
    "    files = os.scandir(base_path)\n",
    "    #  Get the 1st layer of folder\n",
    "    first_folder = []\n",
    "    first_folder_kind = []\n",
    "    for entry in files:\n",
    "        if entry.is_dir():\n",
    "            first_folder.append(entry.path)\n",
    "            first_folder_kind.append(entry.name)\n",
    "    folder_layers.append(first_folder_kind)\n",
    "    folder_list.append(first_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sunflower  finished!\n",
      "tulip  finished!\n",
      "dandelion  finished!\n",
      "daisy  finished!\n",
      "rose  finished!\n"
     ]
    }
   ],
   "source": [
    "datanumber=nbofdata\n",
    "blob=[]\n",
    "blob_nparray=[]\n",
    "image_data=[]\n",
    "conc = 0\n",
    "labels_dict={}\n",
    "fnamelist = {}\n",
    "for entry1 in folder_list[layers_of_folders - 1]:\n",
    "    blob = []\n",
    "    cellname = os.path.basename(os.path.dirname(entry1))  # extract cell name\n",
    "    # print(cellname)\n",
    "    concnames = os.path.basename(entry1)  # extract concentration\n",
    "    # print(concnames)\n",
    "    if concnames in categories:\n",
    "        labels_dict[conc] = concnames\n",
    "        fnamelist = glob.glob(os.path.join(entry1, '*.jpg'))\n",
    "        for filename in fnamelist[0:datanumber]:\n",
    "            im = Image.open(filename)\n",
    "            if im is not None:\n",
    "                if im.mode=='RGB':\n",
    "                    im=im.resize(size,Image.BILINEAR)\n",
    "                    imarray = np.array(im)\n",
    "                    blob.append(imarray)\n",
    "        ind = np.reshape(np.arange(1, len(blob) + 1), (-1, 1))\n",
    "        blob_nparray = np.reshape(np.asarray(blob), (len(blob), blob[1].size))\n",
    "        blob_nparray = np.hstack((blob_nparray, ind, conc * np.ones((len(blob), 1))))\n",
    "        image_data.append(np.asarray(blob_nparray, dtype=np.float32))\n",
    "        print(concnames+'  finished!')\n",
    "        conc += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(categories)):\n",
    "    trytry=image_data[j][:]\n",
    "# Prepare data\n",
    "    LengthT = trytry.shape[0]\n",
    "    trytry_index = trytry[...,-2:-1]\n",
    "    trytry_label = trytry[...,-1:] #['Nega' for x in range(lengthN*4)] #Nega_data[...,-1:]\n",
    "    trytry = trytry[...,:-2]\n",
    "    \n",
    "    # Normalize image by subtracting mean image\n",
    "    trytry -= np.reshape(np.mean(trytry, axis=1), (-1,1))\n",
    "    # Reshape images\n",
    "    trytry = np.reshape(trytry, (trytry.shape[0],256,256,3))\n",
    "    \n",
    "#    # Rotate images\n",
    "#    for i in range(3):\n",
    "#        trytry[LengthT*(i+1):LengthT*(i+2)] = np.rot90(trytry[:LengthT], i+1, (1,2))\n",
    "    # Add channel dimension to fit in Conv2D\n",
    "    trytry = trytry.reshape(-1,256,256,3)\n",
    "    np.random.shuffle(trytry)\n",
    "    trytry_train_upto = round(trytry.shape[0] * 8 / 10)\n",
    "    trytry_test_upto = trytry.shape[0]\n",
    "    if j is 0:\n",
    "        train_data = trytry[:trytry_train_upto]\n",
    "        test_data = trytry[trytry_train_upto:trytry_test_upto]\n",
    "        train_label = trytry_label[:trytry_train_upto]\n",
    "        test_label = trytry_label[trytry_train_upto:trytry_test_upto]\n",
    "        \n",
    "    else:\n",
    "        train_data = np.concatenate((train_data, \n",
    "                                     trytry[:trytry_train_upto]), axis=0)\n",
    "        \n",
    "        test_data = np.concatenate((test_data, \n",
    "                                    trytry[trytry_train_upto:trytry_test_upto]), axis=0)\n",
    "        \n",
    "        train_label = np.concatenate((train_label, \n",
    "                                     trytry_label[:trytry_train_upto]), axis=0)\n",
    "        \n",
    "        \n",
    "        test_label = np.concatenate((test_label, \n",
    "                                    trytry_label[trytry_train_upto:trytry_test_upto]), axis=0)\n",
    "        \n",
    "test_label = keras.utils.to_categorical(test_label, num_classes=len(categories))\n",
    "train_label = keras.utils.to_categorical(train_label, num_classes=len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "temp = list(zip(train_data, train_label))\n",
    "\n",
    "random.shuffle(temp)\n",
    "\n",
    "train_data,train_label = zip(*temp)\n",
    "\n",
    "train_data=np.asarray(train_data)\n",
    "train_label=np.asarray(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = 'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_from_ResNet50():\n",
    "\n",
    "    \"\"\"\n",
    "     Use ResNet-50 (this model's code is from https://www.kaggle.com/cokastefan/keras-resnet-50)\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(ResNet50(include_top=False, pooling='avg', weights=weight_path))\n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(2048, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(len(categories), activation='softmax'))\n",
    "\n",
    "    model.layers[0].trainable = False\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc']) # optimizer=RMSprop(lr=0.001)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 29,907,845\n",
      "Trainable params: 6,309,893\n",
      "Non-trainable params: 23,597,952\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_ResNet50 = create_model_from_ResNet50()\n",
    "model_ResNet50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding rescale, rotation_range, width_shift_range, height_shift_range,\n",
    "# shear_range, zoom_range, and horizontal flip to our ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.4,\n",
    "    height_shift_range=0.4,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "#     rotation_range=40,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Flow training images in batches of 32 using train_datagen generator\n",
    "train_generator = train_datagen.flow(\n",
    "    train_data,\n",
    "    train_label,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow(\n",
    "    test_data,\n",
    "    test_label,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "71/70 - 863s - loss: 1.4263 - acc: 0.7378 - val_loss: 7.5812 - val_acc: 0.1735\n",
      "Epoch 2/60\n",
      "71/70 - 821s - loss: 0.5989 - acc: 0.8198 - val_loss: 2.7385 - val_acc: 0.1681\n",
      "Epoch 3/60\n",
      "71/70 - 818s - loss: 0.4486 - acc: 0.8512 - val_loss: 3.8713 - val_acc: 0.1770\n",
      "Epoch 4/60\n",
      "71/70 - 836s - loss: 0.4136 - acc: 0.8525 - val_loss: 3.6994 - val_acc: 0.2142\n",
      "Epoch 5/60\n",
      "71/70 - 849s - loss: 0.3570 - acc: 0.8756 - val_loss: 3.7341 - val_acc: 0.1770\n",
      "Epoch 6/60\n",
      "71/70 - 878s - loss: 0.3375 - acc: 0.8866 - val_loss: 8.8353 - val_acc: 0.2425\n",
      "Epoch 7/60\n",
      "71/70 - 916s - loss: 0.3298 - acc: 0.8875 - val_loss: 8.0553 - val_acc: 0.1770\n",
      "Epoch 8/60\n",
      "71/70 - 942s - loss: 0.2758 - acc: 0.9021 - val_loss: 5.8414 - val_acc: 0.1770\n",
      "Epoch 9/60\n",
      "71/70 - 910s - loss: 0.2451 - acc: 0.9167 - val_loss: 5.6205 - val_acc: 0.1770\n",
      "Epoch 10/60\n",
      "71/70 - 934s - loss: 0.2650 - acc: 0.9030 - val_loss: 4.2297 - val_acc: 0.1770\n",
      "Epoch 11/60\n",
      "71/70 - 898s - loss: 0.2249 - acc: 0.9203 - val_loss: 4.0855 - val_acc: 0.1770\n",
      "Epoch 12/60\n",
      "71/70 - 858s - loss: 0.2404 - acc: 0.9163 - val_loss: 7.3304 - val_acc: 0.1770\n",
      "Epoch 13/60\n",
      "71/70 - 913s - loss: 0.1917 - acc: 0.9314 - val_loss: 8.9687 - val_acc: 0.1770\n",
      "Epoch 14/60\n",
      "71/70 - 903s - loss: 0.2195 - acc: 0.9207 - val_loss: 8.4188 - val_acc: 0.1770\n",
      "Epoch 15/60\n",
      "71/70 - 863s - loss: 0.2072 - acc: 0.9274 - val_loss: 7.8171 - val_acc: 0.1770\n",
      "Epoch 16/60\n",
      "71/70 - 831s - loss: 0.2488 - acc: 0.9145 - val_loss: 5.9236 - val_acc: 0.2425\n",
      "Epoch 00016: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_ckpt = ModelCheckpoint(filepath=\"./tmp.h5\", \n",
    "                             monitor=\"val_loss\", \n",
    "                             save_best_only=True)\n",
    "\n",
    "EStop = EarlyStopping(monitor='val_acc', min_delta=0, \n",
    "                      patience=10, verbose=1, mode='auto')\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model_ResNet50_info = model_ResNet50.fit_generator(\n",
    "    generator=train_generator, \n",
    "    steps_per_epoch=len(train_data)/batch_size,\n",
    "    epochs=epochs, \n",
    "    validation_steps=len(test_data)/batch_size,\n",
    "    validation_data=val_generator, \n",
    "    verbose=2,\n",
    "    callbacks=[model_ckpt, EStop]\n",
    ")\n",
    "\n",
    "end = time.time()\n",
    "duration = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " model_ResNet50 took 14035.43 seconds (233.9 minutes) to train for 60 epochs\n"
     ]
    }
   ],
   "source": [
    "print ('\\n model_ResNet50 took %0.2f seconds (%0.1f minutes) to train for %d epochs'%(duration, duration/60, epochs) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"./tmp.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (256, 256)\n",
    "nbofdata=2000\n",
    "base_path = r'ml100-03-final/image_data/test/'\n",
    "layers_of_folders=0\n",
    "folder_list=[]    \n",
    "labels=['test']\n",
    "\n",
    "if base_path :\n",
    "    folder_layers=[]\n",
    "    files = os.scandir(base_path)\n",
    "    #  Get the 1st layer of folder\n",
    "    first_folder = []\n",
    "    first_folder_kind = []\n",
    "    for entry in files:\n",
    "        if entry.is_dir():\n",
    "            first_folder.append(entry.path)\n",
    "            first_folder_kind.append(entry.name)\n",
    "    folder_layers.append(first_folder_kind)\n",
    "    folder_list.append(first_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1]\n",
      " [   2]\n",
      " [   3]\n",
      " ...\n",
      " [1998]\n",
      " [1999]\n",
      " [2000]]\n",
      "[[1.190e+02 1.110e+02 1.100e+01 ... 3.000e+00 1.000e+00 0.000e+00]\n",
      " [1.980e+02 2.150e+02 2.270e+02 ... 8.500e+01 2.000e+00 0.000e+00]\n",
      " [3.700e+01 6.300e+01 3.700e+01 ... 3.500e+01 3.000e+00 0.000e+00]\n",
      " ...\n",
      " [1.080e+02 1.230e+02 3.000e+01 ... 0.000e+00 1.998e+03 0.000e+00]\n",
      " [1.380e+02 1.720e+02 1.990e+02 ... 2.000e+00 1.999e+03 0.000e+00]\n",
      " [0.000e+00 0.000e+00 0.000e+00 ... 1.000e+00 2.000e+03 0.000e+00]]\n",
      "test  finished!\n"
     ]
    }
   ],
   "source": [
    "datanumber=nbofdata\n",
    "blob=[]\n",
    "blob_nparray=[]\n",
    "image_data=[]\n",
    "conc = 0\n",
    "fc = 0\n",
    "labels_dict={}\n",
    "fn = {}\n",
    "for entry1 in folder_list[layers_of_folders - 1]:\n",
    "    blob = []\n",
    "    cellname = os.path.basename(os.path.dirname(entry1))  # extract cell name\n",
    "    # print(cellname)\n",
    "    concnames = os.path.basename(entry1)  # extract concentration\n",
    "    # print(concnames)\n",
    "    if concnames in labels:\n",
    "        labels_dict[conc] = concnames\n",
    "        fnamelist = glob.glob(os.path.join(entry1, '*.jpg'))\n",
    "        for filename in fnamelist[0:datanumber]:\n",
    "            im = Image.open(filename)\n",
    "            if im is not None:\n",
    "                if im.mode=='RGB':\n",
    "                    im=im.resize(size,Image.BILINEAR)\n",
    "                    imarray = np.array(im)\n",
    "                    blob.append(imarray)\n",
    "                    fn[fc] = filename\n",
    "                    fc += 1\n",
    "        ind = np.reshape(np.arange(1, len(blob) + 1), (-1, 1))\n",
    "        blob_nparray = np.reshape(np.asarray(blob), (len(blob), blob[1].size))\n",
    "        blob_nparray = np.hstack((blob_nparray, ind, conc * np.ones((len(blob), 1))))\n",
    "        image_data.append(np.asarray(blob_nparray, dtype=np.float32))\n",
    "        print(ind)\n",
    "        print(blob_nparray)\n",
    "        print(concnames+'  finished!')\n",
    "        conc += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ml100-03-final/image_data/test/test/b38d1fef59f487bf8e702c5eab79880d.jpg'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = {}\n",
    "for i in range(2000):\n",
    "    sp[i] = fn[i].split('/')\n",
    "    sp[i] = sp[i][4].split('.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b38d1fef59f487bf8e702c5eab79880d\n",
      "4cd32ea34f68e3b43c73341b8fb3d4c0\n",
      "aabbd368642e6843bb6f15a3afaa9ed0\n",
      "71469fb90f914a3639e7691ea2a64214\n",
      "6c6fc0a1bd638792e341c75949c76428\n",
      "fd2580a8f500b27baf6913759b29c003\n",
      "499790bb426abd7f293270ff2a357984\n",
      "d79a3d0a0e8120333f1ea82aaaad1dd0\n",
      "ff7eac29b6d7a33fbd8009677c3e9c58\n",
      "8ceefea6d56655f1689ae14a20c0f8be\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(sp[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = {}\n",
    "for i in range(2000):\n",
    "    ids[i] = sp[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(labels)):\n",
    "    trytry=image_data[j][:]\n",
    "# Prepare data\n",
    "    LengthT = trytry.shape[0]\n",
    "\n",
    "    trytry_index = trytry[...,-2:-1]\n",
    "\n",
    "    trytry_label = trytry[...,-1:] #['Nega' for x in range(lengthN*4)] #Nega_data[...,-1:]\n",
    "\n",
    "    trytry = trytry[...,:-2]\n",
    "\n",
    "    # Normalize image by subtracting mean image\n",
    "    trytry -= np.reshape(np.mean(trytry, axis=1), (-1,1))\n",
    "    # Reshape images\n",
    "    trytry = np.reshape(trytry, (trytry.shape[0],256,256,3))\n",
    "    \n",
    "#    # Rotate images\n",
    "#    for i in range(3):\n",
    "#        trytry[LengthT*(i+1):LengthT*(i+2)] = np.rot90(trytry[:LengthT], i+1, (1,2))\n",
    "    # Add channel dimension to fit in Conv2D\n",
    "    trytry = trytry.reshape(-1,256,256,3)\n",
    "    trytry_test_upto = trytry.shape[0]\n",
    "    if j is 0:\n",
    "        test_data = trytry[:trytry_test_upto]      \n",
    "    else:     \n",
    "        test_data = np.concatenate((test_data, \n",
    "                                    trytry[trytry_train_upto:trytry_test_upto]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 256, 256, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5982463e-05\n",
      "5.8403054e-17\n",
      "1.913208e-05\n",
      "0.9999449\n",
      "1.0906862e-12\n",
      "0.9999999\n",
      "6.4368e-08\n",
      "3.7248065e-09\n",
      "1.591024e-12\n",
      "6.4554287e-15\n",
      "5.0635878e-09\n",
      "8.1437385e-20\n",
      "1.0\n",
      "3.6114584e-10\n",
      "1.1175388e-17\n",
      "0.99999964\n",
      "6.986518e-12\n",
      "3.262669e-07\n",
      "1.4432815e-09\n",
      "3.1808473e-12\n",
      "0.0037337795\n",
      "1.2769132e-09\n",
      "0.29285094\n",
      "0.7034152\n",
      "4.1086555e-08\n",
      "4.7331164e-06\n",
      "5.399462e-14\n",
      "6.231142e-06\n",
      "0.99998903\n",
      "7.83112e-12\n",
      "1.0\n",
      "2.499573e-20\n",
      "8.275651e-11\n",
      "1.5456631e-12\n",
      "1.5356637e-15\n",
      "5.9839056e-14\n",
      "0.99997413\n",
      "2.499118e-12\n",
      "1.2965865e-13\n",
      "2.5899793e-05\n",
      "4.1844833e-11\n",
      "5.02455e-19\n",
      "1.0\n",
      "3.979181e-09\n",
      "4.276488e-16\n",
      "1.534344e-12\n",
      "0.9999951\n",
      "1.7914715e-15\n",
      "6.8845238e-12\n",
      "4.9317377e-06\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    for j in range(5):\n",
    "        print(predictions[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import array_to_img\n",
    "\n",
    "plt.imshow(array_to_img(test_data[1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_pred = {}\n",
    "for i in range(2000):\n",
    "    for j in range(5):\n",
    "        if predictions[i][j] == np.max(predictions[i]):\n",
    "            if j == 0:\n",
    "                cnn_pred[i] = 3\n",
    "            if j == 1:\n",
    "                cnn_pred[i] = 4\n",
    "            if j == 2:\n",
    "                cnn_pred[i] = 1\n",
    "            if j == 3:\n",
    "                cnn_pred[i] = 0\n",
    "            if j == 4:\n",
    "                cnn_pred[i] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 3,\n",
       " 2: 1,\n",
       " 3: 3,\n",
       " 4: 0,\n",
       " 5: 0,\n",
       " 6: 3,\n",
       " 7: 4,\n",
       " 8: 1,\n",
       " 9: 4,\n",
       " 10: 2,\n",
       " 11: 2,\n",
       " 12: 4,\n",
       " 13: 0,\n",
       " 14: 0,\n",
       " 15: 4,\n",
       " 16: 3,\n",
       " 17: 0,\n",
       " 18: 1,\n",
       " 19: 0,\n",
       " 20: 1,\n",
       " 21: 3,\n",
       " 22: 4,\n",
       " 23: 4,\n",
       " 24: 3,\n",
       " 25: 0,\n",
       " 26: 1,\n",
       " 27: 4,\n",
       " 28: 0,\n",
       " 29: 4,\n",
       " 30: 4,\n",
       " 31: 2,\n",
       " 32: 4,\n",
       " 33: 3,\n",
       " 34: 4,\n",
       " 35: 1,\n",
       " 36: 3,\n",
       " 37: 2,\n",
       " 38: 0,\n",
       " 39: 1,\n",
       " 40: 1,\n",
       " 41: 4,\n",
       " 42: 1,\n",
       " 43: 4,\n",
       " 44: 3,\n",
       " 45: 3,\n",
       " 46: 1,\n",
       " 47: 0,\n",
       " 48: 0,\n",
       " 49: 1,\n",
       " 50: 0,\n",
       " 51: 3,\n",
       " 52: 0,\n",
       " 53: 0,\n",
       " 54: 1,\n",
       " 55: 1,\n",
       " 56: 4,\n",
       " 57: 4,\n",
       " 58: 1,\n",
       " 59: 4,\n",
       " 60: 3,\n",
       " 61: 3,\n",
       " 62: 0,\n",
       " 63: 1,\n",
       " 64: 4,\n",
       " 65: 3,\n",
       " 66: 1,\n",
       " 67: 3,\n",
       " 68: 1,\n",
       " 69: 4,\n",
       " 70: 1,\n",
       " 71: 0,\n",
       " 72: 1,\n",
       " 73: 0,\n",
       " 74: 0,\n",
       " 75: 0,\n",
       " 76: 2,\n",
       " 77: 0,\n",
       " 78: 1,\n",
       " 79: 4,\n",
       " 80: 1,\n",
       " 81: 1,\n",
       " 82: 3,\n",
       " 83: 3,\n",
       " 84: 0,\n",
       " 85: 1,\n",
       " 86: 4,\n",
       " 87: 1,\n",
       " 88: 4,\n",
       " 89: 0,\n",
       " 90: 3,\n",
       " 91: 2,\n",
       " 92: 2,\n",
       " 93: 1,\n",
       " 94: 3,\n",
       " 95: 2,\n",
       " 96: 4,\n",
       " 97: 3,\n",
       " 98: 0,\n",
       " 99: 4,\n",
       " 100: 3,\n",
       " 101: 1,\n",
       " 102: 0,\n",
       " 103: 2,\n",
       " 104: 1,\n",
       " 105: 1,\n",
       " 106: 3,\n",
       " 107: 4,\n",
       " 108: 4,\n",
       " 109: 3,\n",
       " 110: 4,\n",
       " 111: 4,\n",
       " 112: 1,\n",
       " 113: 3,\n",
       " 114: 0,\n",
       " 115: 4,\n",
       " 116: 0,\n",
       " 117: 3,\n",
       " 118: 2,\n",
       " 119: 0,\n",
       " 120: 1,\n",
       " 121: 1,\n",
       " 122: 2,\n",
       " 123: 1,\n",
       " 124: 4,\n",
       " 125: 4,\n",
       " 126: 0,\n",
       " 127: 0,\n",
       " 128: 3,\n",
       " 129: 0,\n",
       " 130: 4,\n",
       " 131: 2,\n",
       " 132: 4,\n",
       " 133: 2,\n",
       " 134: 1,\n",
       " 135: 2,\n",
       " 136: 3,\n",
       " 137: 4,\n",
       " 138: 2,\n",
       " 139: 4,\n",
       " 140: 0,\n",
       " 141: 2,\n",
       " 142: 0,\n",
       " 143: 1,\n",
       " 144: 0,\n",
       " 145: 0,\n",
       " 146: 4,\n",
       " 147: 0,\n",
       " 148: 0,\n",
       " 149: 3,\n",
       " 150: 1,\n",
       " 151: 4,\n",
       " 152: 3,\n",
       " 153: 2,\n",
       " 154: 1,\n",
       " 155: 1,\n",
       " 156: 0,\n",
       " 157: 3,\n",
       " 158: 2,\n",
       " 159: 3,\n",
       " 160: 1,\n",
       " 161: 1,\n",
       " 162: 1,\n",
       " 163: 3,\n",
       " 164: 1,\n",
       " 165: 0,\n",
       " 166: 3,\n",
       " 167: 1,\n",
       " 168: 1,\n",
       " 169: 4,\n",
       " 170: 1,\n",
       " 171: 1,\n",
       " 172: 1,\n",
       " 173: 2,\n",
       " 174: 2,\n",
       " 175: 2,\n",
       " 176: 3,\n",
       " 177: 0,\n",
       " 178: 4,\n",
       " 179: 4,\n",
       " 180: 2,\n",
       " 181: 4,\n",
       " 182: 1,\n",
       " 183: 3,\n",
       " 184: 0,\n",
       " 185: 4,\n",
       " 186: 1,\n",
       " 187: 3,\n",
       " 188: 0,\n",
       " 189: 2,\n",
       " 190: 4,\n",
       " 191: 3,\n",
       " 192: 4,\n",
       " 193: 4,\n",
       " 194: 4,\n",
       " 195: 0,\n",
       " 196: 2,\n",
       " 197: 4,\n",
       " 198: 0,\n",
       " 199: 0,\n",
       " 200: 4,\n",
       " 201: 0,\n",
       " 202: 0,\n",
       " 203: 0,\n",
       " 204: 2,\n",
       " 205: 1,\n",
       " 206: 3,\n",
       " 207: 0,\n",
       " 208: 2,\n",
       " 209: 3,\n",
       " 210: 0,\n",
       " 211: 0,\n",
       " 212: 4,\n",
       " 213: 3,\n",
       " 214: 3,\n",
       " 215: 4,\n",
       " 216: 4,\n",
       " 217: 3,\n",
       " 218: 3,\n",
       " 219: 0,\n",
       " 220: 0,\n",
       " 221: 4,\n",
       " 222: 2,\n",
       " 223: 3,\n",
       " 224: 2,\n",
       " 225: 4,\n",
       " 226: 3,\n",
       " 227: 2,\n",
       " 228: 2,\n",
       " 229: 2,\n",
       " 230: 0,\n",
       " 231: 1,\n",
       " 232: 1,\n",
       " 233: 0,\n",
       " 234: 2,\n",
       " 235: 3,\n",
       " 236: 4,\n",
       " 237: 4,\n",
       " 238: 3,\n",
       " 239: 1,\n",
       " 240: 1,\n",
       " 241: 1,\n",
       " 242: 4,\n",
       " 243: 4,\n",
       " 244: 0,\n",
       " 245: 3,\n",
       " 246: 1,\n",
       " 247: 2,\n",
       " 248: 3,\n",
       " 249: 4,\n",
       " 250: 0,\n",
       " 251: 4,\n",
       " 252: 2,\n",
       " 253: 1,\n",
       " 254: 4,\n",
       " 255: 3,\n",
       " 256: 1,\n",
       " 257: 1,\n",
       " 258: 4,\n",
       " 259: 4,\n",
       " 260: 0,\n",
       " 261: 0,\n",
       " 262: 2,\n",
       " 263: 3,\n",
       " 264: 0,\n",
       " 265: 3,\n",
       " 266: 4,\n",
       " 267: 1,\n",
       " 268: 2,\n",
       " 269: 2,\n",
       " 270: 0,\n",
       " 271: 1,\n",
       " 272: 0,\n",
       " 273: 1,\n",
       " 274: 2,\n",
       " 275: 2,\n",
       " 276: 1,\n",
       " 277: 0,\n",
       " 278: 4,\n",
       " 279: 3,\n",
       " 280: 0,\n",
       " 281: 2,\n",
       " 282: 1,\n",
       " 283: 4,\n",
       " 284: 3,\n",
       " 285: 4,\n",
       " 286: 3,\n",
       " 287: 1,\n",
       " 288: 4,\n",
       " 289: 0,\n",
       " 290: 4,\n",
       " 291: 3,\n",
       " 292: 0,\n",
       " 293: 2,\n",
       " 294: 4,\n",
       " 295: 2,\n",
       " 296: 0,\n",
       " 297: 3,\n",
       " 298: 1,\n",
       " 299: 1,\n",
       " 300: 1,\n",
       " 301: 4,\n",
       " 302: 1,\n",
       " 303: 1,\n",
       " 304: 0,\n",
       " 305: 0,\n",
       " 306: 3,\n",
       " 307: 4,\n",
       " 308: 3,\n",
       " 309: 1,\n",
       " 310: 2,\n",
       " 311: 3,\n",
       " 312: 1,\n",
       " 313: 3,\n",
       " 314: 4,\n",
       " 315: 4,\n",
       " 316: 4,\n",
       " 317: 4,\n",
       " 318: 1,\n",
       " 319: 1,\n",
       " 320: 2,\n",
       " 321: 0,\n",
       " 322: 4,\n",
       " 323: 4,\n",
       " 324: 4,\n",
       " 325: 3,\n",
       " 326: 3,\n",
       " 327: 0,\n",
       " 328: 1,\n",
       " 329: 0,\n",
       " 330: 1,\n",
       " 331: 3,\n",
       " 332: 0,\n",
       " 333: 2,\n",
       " 334: 0,\n",
       " 335: 4,\n",
       " 336: 4,\n",
       " 337: 1,\n",
       " 338: 2,\n",
       " 339: 0,\n",
       " 340: 3,\n",
       " 341: 0,\n",
       " 342: 3,\n",
       " 343: 4,\n",
       " 344: 1,\n",
       " 345: 1,\n",
       " 346: 4,\n",
       " 347: 3,\n",
       " 348: 4,\n",
       " 349: 1,\n",
       " 350: 4,\n",
       " 351: 4,\n",
       " 352: 0,\n",
       " 353: 3,\n",
       " 354: 0,\n",
       " 355: 0,\n",
       " 356: 0,\n",
       " 357: 3,\n",
       " 358: 4,\n",
       " 359: 4,\n",
       " 360: 0,\n",
       " 361: 1,\n",
       " 362: 1,\n",
       " 363: 1,\n",
       " 364: 1,\n",
       " 365: 0,\n",
       " 366: 1,\n",
       " 367: 0,\n",
       " 368: 4,\n",
       " 369: 1,\n",
       " 370: 0,\n",
       " 371: 3,\n",
       " 372: 3,\n",
       " 373: 1,\n",
       " 374: 4,\n",
       " 375: 4,\n",
       " 376: 2,\n",
       " 377: 1,\n",
       " 378: 1,\n",
       " 379: 4,\n",
       " 380: 1,\n",
       " 381: 1,\n",
       " 382: 3,\n",
       " 383: 3,\n",
       " 384: 3,\n",
       " 385: 0,\n",
       " 386: 0,\n",
       " 387: 2,\n",
       " 388: 1,\n",
       " 389: 4,\n",
       " 390: 1,\n",
       " 391: 2,\n",
       " 392: 0,\n",
       " 393: 2,\n",
       " 394: 0,\n",
       " 395: 1,\n",
       " 396: 4,\n",
       " 397: 0,\n",
       " 398: 2,\n",
       " 399: 4,\n",
       " 400: 3,\n",
       " 401: 4,\n",
       " 402: 0,\n",
       " 403: 1,\n",
       " 404: 2,\n",
       " 405: 4,\n",
       " 406: 4,\n",
       " 407: 1,\n",
       " 408: 2,\n",
       " 409: 4,\n",
       " 410: 0,\n",
       " 411: 3,\n",
       " 412: 0,\n",
       " 413: 4,\n",
       " 414: 0,\n",
       " 415: 4,\n",
       " 416: 0,\n",
       " 417: 3,\n",
       " 418: 2,\n",
       " 419: 0,\n",
       " 420: 0,\n",
       " 421: 1,\n",
       " 422: 0,\n",
       " 423: 0,\n",
       " 424: 3,\n",
       " 425: 2,\n",
       " 426: 3,\n",
       " 427: 0,\n",
       " 428: 2,\n",
       " 429: 2,\n",
       " 430: 4,\n",
       " 431: 0,\n",
       " 432: 3,\n",
       " 433: 3,\n",
       " 434: 1,\n",
       " 435: 4,\n",
       " 436: 2,\n",
       " 437: 4,\n",
       " 438: 3,\n",
       " 439: 1,\n",
       " 440: 0,\n",
       " 441: 3,\n",
       " 442: 3,\n",
       " 443: 1,\n",
       " 444: 3,\n",
       " 445: 1,\n",
       " 446: 0,\n",
       " 447: 0,\n",
       " 448: 3,\n",
       " 449: 3,\n",
       " 450: 4,\n",
       " 451: 0,\n",
       " 452: 2,\n",
       " 453: 2,\n",
       " 454: 2,\n",
       " 455: 0,\n",
       " 456: 0,\n",
       " 457: 0,\n",
       " 458: 4,\n",
       " 459: 4,\n",
       " 460: 4,\n",
       " 461: 1,\n",
       " 462: 1,\n",
       " 463: 1,\n",
       " 464: 0,\n",
       " 465: 2,\n",
       " 466: 1,\n",
       " 467: 0,\n",
       " 468: 4,\n",
       " 469: 1,\n",
       " 470: 0,\n",
       " 471: 0,\n",
       " 472: 4,\n",
       " 473: 3,\n",
       " 474: 4,\n",
       " 475: 3,\n",
       " 476: 2,\n",
       " 477: 2,\n",
       " 478: 0,\n",
       " 479: 3,\n",
       " 480: 1,\n",
       " 481: 4,\n",
       " 482: 2,\n",
       " 483: 0,\n",
       " 484: 4,\n",
       " 485: 0,\n",
       " 486: 3,\n",
       " 487: 4,\n",
       " 488: 0,\n",
       " 489: 4,\n",
       " 490: 2,\n",
       " 491: 2,\n",
       " 492: 0,\n",
       " 493: 3,\n",
       " 494: 4,\n",
       " 495: 3,\n",
       " 496: 2,\n",
       " 497: 2,\n",
       " 498: 4,\n",
       " 499: 1,\n",
       " 500: 1,\n",
       " 501: 1,\n",
       " 502: 1,\n",
       " 503: 1,\n",
       " 504: 3,\n",
       " 505: 3,\n",
       " 506: 3,\n",
       " 507: 3,\n",
       " 508: 1,\n",
       " 509: 4,\n",
       " 510: 4,\n",
       " 511: 0,\n",
       " 512: 2,\n",
       " 513: 2,\n",
       " 514: 4,\n",
       " 515: 0,\n",
       " 516: 2,\n",
       " 517: 3,\n",
       " 518: 3,\n",
       " 519: 3,\n",
       " 520: 1,\n",
       " 521: 4,\n",
       " 522: 3,\n",
       " 523: 0,\n",
       " 524: 3,\n",
       " 525: 1,\n",
       " 526: 4,\n",
       " 527: 0,\n",
       " 528: 1,\n",
       " 529: 2,\n",
       " 530: 4,\n",
       " 531: 4,\n",
       " 532: 3,\n",
       " 533: 0,\n",
       " 534: 4,\n",
       " 535: 3,\n",
       " 536: 4,\n",
       " 537: 1,\n",
       " 538: 2,\n",
       " 539: 0,\n",
       " 540: 4,\n",
       " 541: 2,\n",
       " 542: 0,\n",
       " 543: 0,\n",
       " 544: 1,\n",
       " 545: 0,\n",
       " 546: 0,\n",
       " 547: 2,\n",
       " 548: 0,\n",
       " 549: 3,\n",
       " 550: 0,\n",
       " 551: 2,\n",
       " 552: 0,\n",
       " 553: 1,\n",
       " 554: 3,\n",
       " 555: 3,\n",
       " 556: 2,\n",
       " 557: 2,\n",
       " 558: 3,\n",
       " 559: 1,\n",
       " 560: 2,\n",
       " 561: 0,\n",
       " 562: 2,\n",
       " 563: 4,\n",
       " 564: 0,\n",
       " 565: 2,\n",
       " 566: 1,\n",
       " 567: 3,\n",
       " 568: 3,\n",
       " 569: 0,\n",
       " 570: 0,\n",
       " 571: 1,\n",
       " 572: 2,\n",
       " 573: 2,\n",
       " 574: 2,\n",
       " 575: 2,\n",
       " 576: 4,\n",
       " 577: 0,\n",
       " 578: 4,\n",
       " 579: 1,\n",
       " 580: 1,\n",
       " 581: 3,\n",
       " 582: 0,\n",
       " 583: 2,\n",
       " 584: 0,\n",
       " 585: 4,\n",
       " 586: 0,\n",
       " 587: 3,\n",
       " 588: 0,\n",
       " 589: 2,\n",
       " 590: 3,\n",
       " 591: 3,\n",
       " 592: 0,\n",
       " 593: 2,\n",
       " 594: 3,\n",
       " 595: 1,\n",
       " 596: 1,\n",
       " 597: 1,\n",
       " 598: 4,\n",
       " 599: 3,\n",
       " 600: 3,\n",
       " 601: 0,\n",
       " 602: 3,\n",
       " 603: 1,\n",
       " 604: 3,\n",
       " 605: 4,\n",
       " 606: 0,\n",
       " 607: 0,\n",
       " 608: 0,\n",
       " 609: 4,\n",
       " 610: 1,\n",
       " 611: 3,\n",
       " 612: 1,\n",
       " 613: 2,\n",
       " 614: 1,\n",
       " 615: 1,\n",
       " 616: 2,\n",
       " 617: 3,\n",
       " 618: 4,\n",
       " 619: 3,\n",
       " 620: 2,\n",
       " 621: 4,\n",
       " 622: 0,\n",
       " 623: 3,\n",
       " 624: 4,\n",
       " 625: 0,\n",
       " 626: 0,\n",
       " 627: 4,\n",
       " 628: 3,\n",
       " 629: 3,\n",
       " 630: 4,\n",
       " 631: 3,\n",
       " 632: 2,\n",
       " 633: 0,\n",
       " 634: 2,\n",
       " 635: 4,\n",
       " 636: 2,\n",
       " 637: 1,\n",
       " 638: 1,\n",
       " 639: 1,\n",
       " 640: 0,\n",
       " 641: 4,\n",
       " 642: 0,\n",
       " 643: 0,\n",
       " 644: 4,\n",
       " 645: 4,\n",
       " 646: 3,\n",
       " 647: 2,\n",
       " 648: 1,\n",
       " 649: 2,\n",
       " 650: 4,\n",
       " 651: 2,\n",
       " 652: 4,\n",
       " 653: 3,\n",
       " 654: 4,\n",
       " 655: 1,\n",
       " 656: 2,\n",
       " 657: 2,\n",
       " 658: 1,\n",
       " 659: 1,\n",
       " 660: 1,\n",
       " 661: 0,\n",
       " 662: 2,\n",
       " 663: 1,\n",
       " 664: 3,\n",
       " 665: 2,\n",
       " 666: 4,\n",
       " 667: 4,\n",
       " 668: 2,\n",
       " 669: 3,\n",
       " 670: 0,\n",
       " 671: 4,\n",
       " 672: 0,\n",
       " 673: 0,\n",
       " 674: 1,\n",
       " 675: 1,\n",
       " 676: 3,\n",
       " 677: 2,\n",
       " 678: 1,\n",
       " 679: 4,\n",
       " 680: 4,\n",
       " 681: 4,\n",
       " 682: 1,\n",
       " 683: 0,\n",
       " 684: 2,\n",
       " 685: 4,\n",
       " 686: 1,\n",
       " 687: 1,\n",
       " 688: 3,\n",
       " 689: 3,\n",
       " 690: 0,\n",
       " 691: 3,\n",
       " 692: 1,\n",
       " 693: 0,\n",
       " 694: 4,\n",
       " 695: 1,\n",
       " 696: 2,\n",
       " 697: 1,\n",
       " 698: 2,\n",
       " 699: 1,\n",
       " 700: 4,\n",
       " 701: 3,\n",
       " 702: 0,\n",
       " 703: 4,\n",
       " 704: 1,\n",
       " 705: 4,\n",
       " 706: 0,\n",
       " 707: 3,\n",
       " 708: 3,\n",
       " 709: 4,\n",
       " 710: 2,\n",
       " 711: 0,\n",
       " 712: 2,\n",
       " 713: 4,\n",
       " 714: 1,\n",
       " 715: 0,\n",
       " 716: 4,\n",
       " 717: 3,\n",
       " 718: 3,\n",
       " 719: 3,\n",
       " 720: 4,\n",
       " 721: 3,\n",
       " 722: 2,\n",
       " 723: 0,\n",
       " 724: 1,\n",
       " 725: 4,\n",
       " 726: 4,\n",
       " 727: 4,\n",
       " 728: 0,\n",
       " 729: 4,\n",
       " 730: 0,\n",
       " 731: 3,\n",
       " 732: 3,\n",
       " 733: 2,\n",
       " 734: 2,\n",
       " 735: 4,\n",
       " 736: 4,\n",
       " 737: 4,\n",
       " 738: 0,\n",
       " 739: 2,\n",
       " 740: 4,\n",
       " 741: 4,\n",
       " 742: 2,\n",
       " 743: 3,\n",
       " 744: 4,\n",
       " 745: 3,\n",
       " 746: 2,\n",
       " 747: 3,\n",
       " 748: 3,\n",
       " 749: 3,\n",
       " 750: 1,\n",
       " 751: 4,\n",
       " 752: 3,\n",
       " 753: 4,\n",
       " 754: 3,\n",
       " 755: 3,\n",
       " 756: 3,\n",
       " 757: 0,\n",
       " 758: 1,\n",
       " 759: 0,\n",
       " 760: 4,\n",
       " 761: 4,\n",
       " 762: 0,\n",
       " 763: 3,\n",
       " 764: 2,\n",
       " 765: 3,\n",
       " 766: 3,\n",
       " 767: 3,\n",
       " 768: 4,\n",
       " 769: 3,\n",
       " 770: 2,\n",
       " 771: 1,\n",
       " 772: 3,\n",
       " 773: 4,\n",
       " 774: 4,\n",
       " 775: 3,\n",
       " 776: 4,\n",
       " 777: 0,\n",
       " 778: 4,\n",
       " 779: 1,\n",
       " 780: 0,\n",
       " 781: 2,\n",
       " 782: 1,\n",
       " 783: 1,\n",
       " 784: 4,\n",
       " 785: 1,\n",
       " 786: 4,\n",
       " 787: 0,\n",
       " 788: 1,\n",
       " 789: 0,\n",
       " 790: 0,\n",
       " 791: 2,\n",
       " 792: 1,\n",
       " 793: 2,\n",
       " 794: 3,\n",
       " 795: 3,\n",
       " 796: 1,\n",
       " 797: 4,\n",
       " 798: 3,\n",
       " 799: 1,\n",
       " 800: 0,\n",
       " 801: 1,\n",
       " 802: 4,\n",
       " 803: 1,\n",
       " 804: 4,\n",
       " 805: 2,\n",
       " 806: 3,\n",
       " 807: 0,\n",
       " 808: 4,\n",
       " 809: 3,\n",
       " 810: 4,\n",
       " 811: 3,\n",
       " 812: 0,\n",
       " 813: 4,\n",
       " 814: 2,\n",
       " 815: 1,\n",
       " 816: 0,\n",
       " 817: 0,\n",
       " 818: 1,\n",
       " 819: 2,\n",
       " 820: 2,\n",
       " 821: 4,\n",
       " 822: 1,\n",
       " 823: 2,\n",
       " 824: 0,\n",
       " 825: 2,\n",
       " 826: 0,\n",
       " 827: 3,\n",
       " 828: 4,\n",
       " 829: 1,\n",
       " 830: 1,\n",
       " 831: 0,\n",
       " 832: 4,\n",
       " 833: 0,\n",
       " 834: 3,\n",
       " 835: 1,\n",
       " 836: 4,\n",
       " 837: 4,\n",
       " 838: 3,\n",
       " 839: 0,\n",
       " 840: 0,\n",
       " 841: 2,\n",
       " 842: 1,\n",
       " 843: 0,\n",
       " 844: 1,\n",
       " 845: 2,\n",
       " 846: 4,\n",
       " 847: 0,\n",
       " 848: 4,\n",
       " 849: 1,\n",
       " 850: 3,\n",
       " 851: 1,\n",
       " 852: 0,\n",
       " 853: 2,\n",
       " 854: 3,\n",
       " 855: 4,\n",
       " 856: 1,\n",
       " 857: 3,\n",
       " 858: 1,\n",
       " 859: 4,\n",
       " 860: 0,\n",
       " 861: 3,\n",
       " 862: 4,\n",
       " 863: 4,\n",
       " 864: 4,\n",
       " 865: 4,\n",
       " 866: 3,\n",
       " 867: 4,\n",
       " 868: 3,\n",
       " 869: 2,\n",
       " 870: 4,\n",
       " 871: 1,\n",
       " 872: 0,\n",
       " 873: 2,\n",
       " 874: 0,\n",
       " 875: 3,\n",
       " 876: 1,\n",
       " 877: 4,\n",
       " 878: 0,\n",
       " 879: 1,\n",
       " 880: 1,\n",
       " 881: 1,\n",
       " 882: 1,\n",
       " 883: 1,\n",
       " 884: 1,\n",
       " 885: 3,\n",
       " 886: 2,\n",
       " 887: 1,\n",
       " 888: 4,\n",
       " 889: 1,\n",
       " 890: 4,\n",
       " 891: 1,\n",
       " 892: 3,\n",
       " 893: 2,\n",
       " 894: 4,\n",
       " 895: 0,\n",
       " 896: 3,\n",
       " 897: 2,\n",
       " 898: 4,\n",
       " 899: 4,\n",
       " 900: 2,\n",
       " 901: 4,\n",
       " 902: 2,\n",
       " 903: 4,\n",
       " 904: 2,\n",
       " 905: 4,\n",
       " 906: 2,\n",
       " 907: 2,\n",
       " 908: 1,\n",
       " 909: 1,\n",
       " 910: 0,\n",
       " 911: 4,\n",
       " 912: 3,\n",
       " 913: 4,\n",
       " 914: 0,\n",
       " 915: 1,\n",
       " 916: 4,\n",
       " 917: 4,\n",
       " 918: 0,\n",
       " 919: 0,\n",
       " 920: 4,\n",
       " 921: 4,\n",
       " 922: 1,\n",
       " 923: 2,\n",
       " 924: 3,\n",
       " 925: 2,\n",
       " 926: 4,\n",
       " 927: 1,\n",
       " 928: 4,\n",
       " 929: 1,\n",
       " 930: 1,\n",
       " 931: 1,\n",
       " 932: 0,\n",
       " 933: 1,\n",
       " 934: 0,\n",
       " 935: 0,\n",
       " 936: 4,\n",
       " 937: 3,\n",
       " 938: 0,\n",
       " 939: 3,\n",
       " 940: 4,\n",
       " 941: 4,\n",
       " 942: 1,\n",
       " 943: 2,\n",
       " 944: 4,\n",
       " 945: 3,\n",
       " 946: 2,\n",
       " 947: 1,\n",
       " 948: 2,\n",
       " 949: 4,\n",
       " 950: 3,\n",
       " 951: 1,\n",
       " 952: 4,\n",
       " 953: 1,\n",
       " 954: 0,\n",
       " 955: 3,\n",
       " 956: 4,\n",
       " 957: 4,\n",
       " 958: 1,\n",
       " 959: 3,\n",
       " 960: 2,\n",
       " 961: 3,\n",
       " 962: 4,\n",
       " 963: 2,\n",
       " 964: 0,\n",
       " 965: 0,\n",
       " 966: 4,\n",
       " 967: 1,\n",
       " 968: 4,\n",
       " 969: 0,\n",
       " 970: 4,\n",
       " 971: 0,\n",
       " 972: 1,\n",
       " 973: 2,\n",
       " 974: 1,\n",
       " 975: 2,\n",
       " 976: 1,\n",
       " 977: 1,\n",
       " 978: 4,\n",
       " 979: 0,\n",
       " 980: 1,\n",
       " 981: 0,\n",
       " 982: 1,\n",
       " 983: 0,\n",
       " 984: 0,\n",
       " 985: 1,\n",
       " 986: 4,\n",
       " 987: 0,\n",
       " 988: 2,\n",
       " 989: 2,\n",
       " 990: 0,\n",
       " 991: 3,\n",
       " 992: 2,\n",
       " 993: 3,\n",
       " 994: 1,\n",
       " 995: 0,\n",
       " 996: 3,\n",
       " 997: 1,\n",
       " 998: 3,\n",
       " 999: 3,\n",
       " ...}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "submit = pd.DataFrame({'id': ids, 'flower_class': cnn_pred})\n",
    "header = [\"id\", \"flower_class\"]\n",
    "submit.to_csv('cnn_resnet_predict_256.csv', columns = header, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
