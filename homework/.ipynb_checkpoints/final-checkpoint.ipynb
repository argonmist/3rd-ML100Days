{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import  img_to_array, load_img\n",
    "from PIL import Image\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_labels = {\"daisy\":0, \"dandelion\":1, \"rose\": 2, \"sunflower\":3, \"tulip\": 4}\n",
    "size = (128, 128)\n",
    "nbofdata=700\n",
    "base_path = r'ml100-03-final/image_data/train/'\n",
    "layers_of_folders=0\n",
    "folder_list=[]    \n",
    "labels=['daisy','dandelion', 'rose', 'sunflower', 'tulip']\n",
    "\n",
    "if base_path :\n",
    "    folder_layers=[]\n",
    "    files = os.scandir(base_path)\n",
    "    #  Get the 1st layer of folder\n",
    "    first_folder = []\n",
    "    first_folder_kind = []\n",
    "    for entry in files:\n",
    "        if entry.is_dir():\n",
    "            first_folder.append(entry.path)\n",
    "            first_folder_kind.append(entry.name)\n",
    "    folder_layers.append(first_folder_kind)\n",
    "    folder_list.append(first_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ml100-03-final/image_data/train/sunflower',\n",
       "  'ml100-03-final/image_data/train/tulip',\n",
       "  'ml100-03-final/image_data/train/dandelion',\n",
       "  'ml100-03-final/image_data/train/daisy',\n",
       "  'ml100-03-final/image_data/train/rose']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['sunflower', 'tulip', 'dandelion', 'daisy', 'rose']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sunflower', 'tulip', 'dandelion', 'daisy', 'rose']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_folder_kind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ml100-03-final/image_data/train/sunflower',\n",
       " 'ml100-03-final/image_data/train/tulip',\n",
       " 'ml100-03-final/image_data/train/dandelion',\n",
       " 'ml100-03-final/image_data/train/daisy',\n",
       " 'ml100-03-final/image_data/train/rose']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sunflower  finished!\n",
      "tulip  finished!\n",
      "dandelion  finished!\n",
      "daisy  finished!\n",
      "rose  finished!\n"
     ]
    }
   ],
   "source": [
    "datanumber=nbofdata\n",
    "blob=[]\n",
    "blob_nparray=[]\n",
    "image_data=[]\n",
    "conc = 0\n",
    "labels_dict={}\n",
    "for entry1 in folder_list[layers_of_folders - 1]:\n",
    "    blob = []\n",
    "    cellname = os.path.basename(os.path.dirname(entry1))  # extract cell name\n",
    "    # print(cellname)\n",
    "    concnames = os.path.basename(entry1)  # extract concentration\n",
    "    # print(concnames)\n",
    "    if concnames in labels:\n",
    "        labels_dict[conc] = concnames\n",
    "        fnamelist = glob.glob(os.path.join(entry1, '*.jpg'))\n",
    "        for filename in fnamelist[0:datanumber]:\n",
    "            im = Image.open(filename)\n",
    "            if im is not None:\n",
    "                if im.mode=='RGB':\n",
    "                    im=im.resize(size,Image.BILINEAR)\n",
    "                    imarray = np.array(im)\n",
    "                    blob.append(imarray)\n",
    "        ind = np.reshape(np.arange(1, len(blob) + 1), (-1, 1))\n",
    "        blob_nparray = np.reshape(np.asarray(blob), (len(blob), blob[1].size))\n",
    "        blob_nparray = np.hstack((blob_nparray, ind, conc * np.ones((len(blob), 1))))\n",
    "        image_data.append(np.asarray(blob_nparray, dtype=np.float32))\n",
    "        print(concnames+'  finished!')\n",
    "        conc += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[  5.,   1.,   2., ...,   8.,   1.,   0.],\n",
       "        [102., 170., 209., ..., 217.,   2.,   0.],\n",
       "        [ 40.,  37.,  45., ...,  10.,   3.,   0.],\n",
       "        ...,\n",
       "        [ 86., 133., 177., ...,  22., 486.,   0.],\n",
       "        [ 74., 107.,  56., ...,  15., 487.,   0.],\n",
       "        [231., 242., 254., ...,  17., 488.,   0.]], dtype=float32),\n",
       " array([[140., 138., 223., ..., 169.,   1.,   1.],\n",
       "        [120., 142.,  46., ...,   1.,   2.,   1.],\n",
       "        [ 66.,  88.,  26., ...,  19.,   3.,   1.],\n",
       "        ...,\n",
       "        [222., 125.,  55., ...,  61., 631.,   1.],\n",
       "        [  1.,  23.,   3., ...,  40., 632.,   1.],\n",
       "        [202., 174., 145., ...,  61., 633.,   1.]], dtype=float32),\n",
       " array([[  1.,   1.,   1., ...,   2.,   1.,   2.],\n",
       "        [ 45.,  44.,  39., ...,  38.,   2.,   2.],\n",
       "        [ 24.,  25.,  19., ...,  29.,   3.,   2.],\n",
       "        ...,\n",
       "        [ 25.,  40.,  21., ...,  21., 685.,   2.],\n",
       "        [192., 141., 128., ..., 145., 686.,   2.],\n",
       "        [171., 110.,  51., ...,  13., 687.,   2.]], dtype=float32),\n",
       " array([[128., 155., 223., ...,   1.,   1.,   3.],\n",
       "        [ 29.,  35.,  21., ...,  31.,   2.,   3.],\n",
       "        [224., 224., 224., ..., 207.,   3.,   3.],\n",
       "        ...,\n",
       "        [ 41.,  41.,  41., ...,  40., 498.,   3.],\n",
       "        [ 40.,  62.,  37., ...,  10., 499.,   3.],\n",
       "        [255., 255., 255., ..., 255., 500.,   3.]], dtype=float32),\n",
       " array([[  2.,   2.,   4., ...,   1.,   1.,   4.],\n",
       "        [158., 162., 163., ..., 127.,   2.,   4.],\n",
       "        [254., 254., 254., ..., 255.,   3.,   4.],\n",
       "        ...,\n",
       "        [139., 156., 174., ...,   1., 513.,   4.],\n",
       "        [ 52.,  58.,  34., ...,   0., 514.,   4.],\n",
       "        [195., 163., 168., ...,   1., 515.,   4.]], dtype=float32)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(labels)):\n",
    "    trytry=image_data[j][:]\n",
    "# Prepare data\n",
    "    LengthT = trytry.shape[0]\n",
    "    trytry_index = trytry[...,-2:-1]\n",
    "    trytry_label = trytry[...,-1:] #['Nega' for x in range(lengthN*4)] #Nega_data[...,-1:]\n",
    "    trytry = trytry[...,:-2]\n",
    "    \n",
    "    # Normalize image by subtracting mean image\n",
    "    trytry -= np.reshape(np.mean(trytry, axis=1), (-1,1))\n",
    "    # Reshape images\n",
    "    trytry = np.reshape(trytry, (trytry.shape[0],128,128,3))\n",
    "    \n",
    "#    # Rotate images\n",
    "#    for i in range(3):\n",
    "#        trytry[LengthT*(i+1):LengthT*(i+2)] = np.rot90(trytry[:LengthT], i+1, (1,2))\n",
    "    # Add channel dimension to fit in Conv2D\n",
    "    trytry = trytry.reshape(-1,128,128,3)\n",
    "    np.random.shuffle(trytry)\n",
    "    trytry_train_upto = round(trytry.shape[0] * 8 / 10)\n",
    "    trytry_test_upto = trytry.shape[0]\n",
    "    if j is 0:\n",
    "        train_data = trytry[:trytry_train_upto]\n",
    "        test_data = trytry[trytry_train_upto:trytry_test_upto]\n",
    "        train_label = trytry_label[:trytry_train_upto]\n",
    "        test_label = trytry_label[trytry_train_upto:trytry_test_upto]\n",
    "        \n",
    "    else:\n",
    "        train_data = np.concatenate((train_data, \n",
    "                                     trytry[:trytry_train_upto]), axis=0)\n",
    "        \n",
    "        test_data = np.concatenate((test_data, \n",
    "                                    trytry[trytry_train_upto:trytry_test_upto]), axis=0)\n",
    "        \n",
    "        train_label = np.concatenate((train_label, \n",
    "                                     trytry_label[:trytry_train_upto]), axis=0)\n",
    "        \n",
    "        \n",
    "        test_label = np.concatenate((test_label, \n",
    "                                    trytry_label[trytry_train_upto:trytry_test_upto]), axis=0)\n",
    "        \n",
    "test_label = keras.utils.to_categorical(test_label, num_classes=len(labels))\n",
    "train_label = keras.utils.to_categorical(train_label, num_classes=len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "temp = list(zip(train_data, train_label))\n",
    "\n",
    "random.shuffle(temp)\n",
    "\n",
    "train_data,train_label = zip(*temp)\n",
    "\n",
    "train_data=np.asarray(train_data)\n",
    "train_label=np.asarray(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32 samples, validate on 8 samples\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 5.6928 - accuracy: 0.5125 - val_loss: 9.8882 - val_accuracy: 0.7750\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,val_loss,accuracy,val_accuracy\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 3s 81ms/step - loss: 40.8516 - accuracy: 0.6875 - val_loss: 5.5455 - val_accuracy: 0.8000\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 3s 83ms/step - loss: 17.3459 - accuracy: 0.6750 - val_loss: 2.9785 - val_accuracy: 0.6750\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 3s 81ms/step - loss: 13.3009 - accuracy: 0.6438 - val_loss: 1.4546 - val_accuracy: 0.8000\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 3s 92ms/step - loss: 5.3996 - accuracy: 0.6500 - val_loss: 1.3353 - val_accuracy: 0.8000\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 3s 81ms/step - loss: 4.8625 - accuracy: 0.6500 - val_loss: 0.8096 - val_accuracy: 0.8000\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 3s 82ms/step - loss: 4.6757 - accuracy: 0.6500 - val_loss: 0.6243 - val_accuracy: 0.8000\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 3s 89ms/step - loss: 3.0464 - accuracy: 0.6438 - val_loss: 0.7648 - val_accuracy: 0.6500\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 3s 83ms/step - loss: 2.6388 - accuracy: 0.6187 - val_loss: 0.5668 - val_accuracy: 0.8000\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 1.5543 - accuracy: 0.6688 - val_loss: 0.5617 - val_accuracy: 0.7000\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.8705 - accuracy: 0.7625 - val_loss: 0.5640 - val_accuracy: 0.8000\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 3s 104ms/step - loss: 0.7103 - accuracy: 0.7000 - val_loss: 0.5684 - val_accuracy: 0.7500\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 3s 100ms/step - loss: 0.7966 - accuracy: 0.7250 - val_loss: 0.6054 - val_accuracy: 0.7750\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 3s 90ms/step - loss: 1.0906 - accuracy: 0.7062 - val_loss: 0.6337 - val_accuracy: 0.7250\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 3s 98ms/step - loss: 0.6985 - accuracy: 0.7063 - val_loss: 0.6457 - val_accuracy: 0.5250\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 3s 93ms/step - loss: 0.7305 - accuracy: 0.6500 - val_loss: 0.6752 - val_accuracy: 0.5750\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 2s 73ms/step - loss: 0.7080 - accuracy: 0.6313 - val_loss: 0.6631 - val_accuracy: 0.7250\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 3s 81ms/step - loss: 0.5768 - accuracy: 0.7063 - val_loss: 0.6625 - val_accuracy: 0.6750\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.6304 - accuracy: 0.7063 - val_loss: 0.6516 - val_accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.6647 - accuracy: 0.6750 - val_loss: 0.6044 - val_accuracy: 0.8000\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.6643 - accuracy: 0.7000 - val_loss: 0.6048 - val_accuracy: 0.7500\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.6520 - accuracy: 0.7125 - val_loss: 0.6340 - val_accuracy: 0.6500\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.7732 - accuracy: 0.6375 - val_loss: 0.5948 - val_accuracy: 0.7250\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.6443 - accuracy: 0.7125 - val_loss: 0.6095 - val_accuracy: 0.7500\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.7332 - accuracy: 0.7437 - val_loss: 0.6724 - val_accuracy: 0.5750\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.9331 - accuracy: 0.5687 - val_loss: 0.6538 - val_accuracy: 0.6000\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.7319 - accuracy: 0.6313 - val_loss: 0.6258 - val_accuracy: 0.7500\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.6620 - accuracy: 0.6313 - val_loss: 0.6620 - val_accuracy: 0.8000\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 3s 96ms/step - loss: 0.6456 - accuracy: 0.6875 - val_loss: 0.6575 - val_accuracy: 0.6750\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.5588 - accuracy: 0.7500 - val_loss: 0.6667 - val_accuracy: 0.7250\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 3s 84ms/step - loss: 0.6662 - accuracy: 0.6875 - val_loss: 0.6497 - val_accuracy: 0.7000\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 3s 81ms/step - loss: 0.6633 - accuracy: 0.6562 - val_loss: 0.6481 - val_accuracy: 0.7750\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.5415 - accuracy: 0.7687 - val_loss: 0.6480 - val_accuracy: 0.6750\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 3s 81ms/step - loss: 0.5965 - accuracy: 0.7125 - val_loss: 0.5841 - val_accuracy: 0.7750\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 3s 91ms/step - loss: 0.6344 - accuracy: 0.7063 - val_loss: 0.6145 - val_accuracy: 0.7750\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 3s 82ms/step - loss: 0.5410 - accuracy: 0.7563 - val_loss: 0.6275 - val_accuracy: 0.7250\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 3s 82ms/step - loss: 0.6421 - accuracy: 0.6625 - val_loss: 0.6513 - val_accuracy: 0.7750\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.6097 - accuracy: 0.7625 - val_loss: 0.6391 - val_accuracy: 0.6750\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.6450 - accuracy: 0.6875 - val_loss: 0.6751 - val_accuracy: 0.7000\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 3s 83ms/step - loss: 0.6054 - accuracy: 0.7375 - val_loss: 0.6522 - val_accuracy: 0.7000\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 3s 83ms/step - loss: 0.6403 - accuracy: 0.7312 - val_loss: 0.6644 - val_accuracy: 0.7000\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.5638 - accuracy: 0.7375 - val_loss: 0.6549 - val_accuracy: 0.7000\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.5198 - accuracy: 0.7812 - val_loss: 0.6599 - val_accuracy: 0.7250\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 3s 81ms/step - loss: 0.5277 - accuracy: 0.7500 - val_loss: 0.6435 - val_accuracy: 0.8000\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.5554 - accuracy: 0.7687 - val_loss: 0.6538 - val_accuracy: 0.7250\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 3s 81ms/step - loss: 0.5518 - accuracy: 0.7375 - val_loss: 0.6095 - val_accuracy: 0.7500\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.6244 - accuracy: 0.7188 - val_loss: 0.6255 - val_accuracy: 0.7000\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.5019 - accuracy: 0.7625 - val_loss: 0.6273 - val_accuracy: 0.7500\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 3s 81ms/step - loss: 0.6066 - accuracy: 0.6938 - val_loss: 0.5883 - val_accuracy: 0.8000\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.7531 - accuracy: 0.7625 - val_loss: 0.6695 - val_accuracy: 0.6750\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 3s 83ms/step - loss: 0.5685 - accuracy: 0.7000 - val_loss: 0.6397 - val_accuracy: 0.7500\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.5489 - accuracy: 0.8000 - val_loss: 0.6351 - val_accuracy: 0.7500\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 3s 83ms/step - loss: 0.5293 - accuracy: 0.7812 - val_loss: 0.6210 - val_accuracy: 0.7750\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.5552 - accuracy: 0.7188 - val_loss: 0.5747 - val_accuracy: 0.7500\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.6426 - accuracy: 0.7500 - val_loss: 0.6678 - val_accuracy: 0.7500\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.5580 - accuracy: 0.7500 - val_loss: 0.6662 - val_accuracy: 0.6750\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 3s 83ms/step - loss: 0.6085 - accuracy: 0.7688 - val_loss: 0.6550 - val_accuracy: 0.7750\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.5396 - accuracy: 0.7500 - val_loss: 0.6345 - val_accuracy: 0.7250\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.5188 - accuracy: 0.7563 - val_loss: 0.6723 - val_accuracy: 0.7250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.5851 - accuracy: 0.7500 - val_loss: 0.6631 - val_accuracy: 0.6250\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 3s 89ms/step - loss: 0.5891 - accuracy: 0.7437 - val_loss: 0.6727 - val_accuracy: 0.7000\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 3s 90ms/step - loss: 0.6108 - accuracy: 0.7500 - val_loss: 0.6526 - val_accuracy: 0.7500\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 3s 83ms/step - loss: 0.5459 - accuracy: 0.7375 - val_loss: 0.6423 - val_accuracy: 0.7250\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 3s 81ms/step - loss: 0.4939 - accuracy: 0.7937 - val_loss: 0.6491 - val_accuracy: 0.6250\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 3s 82ms/step - loss: 0.4743 - accuracy: 0.7938 - val_loss: 0.6126 - val_accuracy: 0.7750\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.5543 - accuracy: 0.7250 - val_loss: 0.5880 - val_accuracy: 0.8000\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 3s 81ms/step - loss: 0.5996 - accuracy: 0.7437 - val_loss: 0.6278 - val_accuracy: 0.8250\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.4878 - accuracy: 0.8062 - val_loss: 0.6009 - val_accuracy: 0.8000\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 3s 84ms/step - loss: 0.5292 - accuracy: 0.7750 - val_loss: 0.6152 - val_accuracy: 0.7750\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.5213 - accuracy: 0.7500 - val_loss: 0.6330 - val_accuracy: 0.7000\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.4440 - accuracy: 0.7812 - val_loss: 0.5917 - val_accuracy: 0.8000\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 3s 81ms/step - loss: 0.4408 - accuracy: 0.8125 - val_loss: 0.6249 - val_accuracy: 0.7500\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.4960 - accuracy: 0.7750 - val_loss: 0.6150 - val_accuracy: 0.8250\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.5500 - accuracy: 0.7625 - val_loss: 0.6035 - val_accuracy: 0.8000\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.4236 - accuracy: 0.8188 - val_loss: 0.5730 - val_accuracy: 0.8000\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.4872 - accuracy: 0.7063 - val_loss: 0.6020 - val_accuracy: 0.7750\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.4453 - accuracy: 0.7688 - val_loss: 0.5811 - val_accuracy: 0.8250\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 3s 81ms/step - loss: 0.4406 - accuracy: 0.7937 - val_loss: 0.6009 - val_accuracy: 0.7250\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 3s 82ms/step - loss: 0.4485 - accuracy: 0.8125 - val_loss: 0.6009 - val_accuracy: 0.7750\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.5207 - accuracy: 0.7812 - val_loss: 0.6098 - val_accuracy: 0.7250\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 3s 78ms/step - loss: 0.4637 - accuracy: 0.7500 - val_loss: 0.6092 - val_accuracy: 0.7250\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.4213 - accuracy: 0.8250 - val_loss: 0.6111 - val_accuracy: 0.7500\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 3s 78ms/step - loss: 0.4405 - accuracy: 0.7875 - val_loss: 0.6046 - val_accuracy: 0.8000\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 3s 87ms/step - loss: 0.4285 - accuracy: 0.8250 - val_loss: 0.5945 - val_accuracy: 0.7500\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 3s 89ms/step - loss: 0.4927 - accuracy: 0.7500 - val_loss: 0.5903 - val_accuracy: 0.7250\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.4863 - accuracy: 0.7750 - val_loss: 0.6062 - val_accuracy: 0.7750\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 3s 83ms/step - loss: 0.4064 - accuracy: 0.8375 - val_loss: 0.5478 - val_accuracy: 0.8250\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.4229 - accuracy: 0.8000 - val_loss: 0.5808 - val_accuracy: 0.7750\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.3964 - accuracy: 0.7937 - val_loss: 0.5576 - val_accuracy: 0.7500\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 3s 82ms/step - loss: 0.4446 - accuracy: 0.7875 - val_loss: 0.5752 - val_accuracy: 0.7750\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.3792 - accuracy: 0.8250 - val_loss: 0.5871 - val_accuracy: 0.7500\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 3s 88ms/step - loss: 0.4415 - accuracy: 0.8062 - val_loss: 0.5905 - val_accuracy: 0.7000\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.3902 - accuracy: 0.8000 - val_loss: 0.5880 - val_accuracy: 0.7750\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 3s 81ms/step - loss: 0.3741 - accuracy: 0.8500 - val_loss: 0.5683 - val_accuracy: 0.8000\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 3s 84ms/step - loss: 0.3937 - accuracy: 0.7937 - val_loss: 0.5767 - val_accuracy: 0.7000\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 3s 81ms/step - loss: 0.3502 - accuracy: 0.8250 - val_loss: 0.5806 - val_accuracy: 0.7750\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.3701 - accuracy: 0.8937 - val_loss: 0.5694 - val_accuracy: 0.7250\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 3s 89ms/step - loss: 0.2907 - accuracy: 0.8687 - val_loss: 0.5614 - val_accuracy: 0.7500\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 3s 84ms/step - loss: 0.3027 - accuracy: 0.8438 - val_loss: 0.5728 - val_accuracy: 0.7500\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 3s 86ms/step - loss: 0.2904 - accuracy: 0.8625 - val_loss: 0.5612 - val_accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD,RMSprop\n",
    "# Generate model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(128,128,3),padding='same',name='block1_conv2_1'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu',padding='same',name='block1_conv2_2'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),name='block1_MaxPooling'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu',padding='same',name='block2_conv2_1'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu',padding='same',name='block2_conv2_2'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),name='block2_MaxPooling'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu',name='final_output_1'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu',name='final_output_2'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='sigmoid',name='class_output'))\n",
    "optimizer = RMSprop(lr=1e-4)\n",
    "objective = 'binary_crossentropy'\n",
    "model.compile(loss=objective, optimizer=optimizer, metrics=['accuracy'])\n",
    "EStop = EarlyStopping(monitor='val_acc', min_delta=0, \n",
    "                      patience=10, verbose=1, mode='auto')\n",
    "history = model.fit(train_data, train_label, batch_size=64, epochs=100,shuffle=True, validation_split=0.2,callbacks=[EStop])\n",
    "model.save('flower_model.h5') \n",
    "predictions=model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import array_to_img\n",
    "i=4\n",
    "predictions.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
